{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1c1df3f-3322-4c4b-a56d-2a8289e4fff3",
   "metadata": {},
   "source": [
    "# Round 2 Model outputs\n",
    "\n",
    "For Round 2 the following adjustments were made from Round 2:\n",
    "\n",
    "__NER & CR:__\n",
    "\n",
    "- Because both models are using spaCy both components can be run simultaneously\n",
    "- Etc - add more descriptions!\n",
    "\n",
    "__REX:__\n",
    "\n",
    "- Self-relations were removed\n",
    "- The alternate_name relation for Flair was re-included as it proved very useful in disambiguation\n",
    "\n",
    "When running on GPU one can use ```watch -n 1 nvidia-smi``` to monitor GPU usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d343e8-1947-4b87-8665-979ffefacdc2",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "030a8ce0-d3f6-4f61-a135-21d66547cf1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "from kg_builder import kg\n",
    "from kg_builder import ner\n",
    "from kg_builder import cr\n",
    "from kg_builder import rex\n",
    "from kg_builder import get_wd_relation_data\n",
    "from kg_builder import chunk_long_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b686a50-cb9f-4644-adb6-0ef03293022d",
   "metadata": {},
   "source": [
    "## Import data and make Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80a1d804-1086-44b4-bf0d-8254b862516e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import (sample) data\n",
    "df = pd.read_parquet('source_data/sample_text_30.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6989eed8-8f35-431a-b849-fc2640f89d26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make a list of Article instances\n",
    "articles = kg.make_articles(df=df)\n",
    "\n",
    "# Just get 3 to test with on CPU - comment out for full run\n",
    "# articles = articles[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca9814a-8f8a-43db-9607-8085e9ff8654",
   "metadata": {},
   "source": [
    "## Run NER and CR on articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b0bf135-bfe7-4acf-abfb-45b1f05e4781",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "08/02/2024 11:57:47 - INFO - \t missing_keys: []\n",
      "08/02/2024 11:57:47 - INFO - \t unexpected_keys: []\n",
      "08/02/2024 11:57:47 - INFO - \t mismatched_keys: []\n",
      "08/02/2024 11:57:47 - INFO - \t error_msgs: []\n",
      "08/02/2024 11:57:47 - INFO - \t Model Parameters: 90.5M, Transformer: 82.1M, Coref head: 8.4M\n",
      "08/02/2024 11:57:50 - INFO - \t Tokenize 5 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10860a68142142b0be093bfbd7da092b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/02/2024 11:57:53 - INFO - \t ***** Running Inference on 5 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "529c26f5d1744f53b1bda8f3581920fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/02/2024 11:57:54 - INFO - \t Tokenize 5 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f481b649d4dd4b1eafe89d1916194313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/02/2024 11:57:57 - INFO - \t ***** Running Inference on 5 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f2d90549c545be8b397cf7ff250c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/02/2024 11:57:57 - INFO - \t Tokenize 5 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7023695c3c44be8a96e84515af02207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/02/2024 11:58:00 - INFO - \t ***** Running Inference on 5 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c845e5b0eecb4c25aabae9356944bdfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/02/2024 11:58:01 - INFO - \t Tokenize 5 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8646be3e11524b778d91373312ae6a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/02/2024 11:58:04 - INFO - \t ***** Running Inference on 5 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "458d3db77e204e31821264895241ee6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/02/2024 11:58:05 - INFO - \t Tokenize 5 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f13684d0990541f28854f7f2cb008ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/02/2024 11:58:08 - INFO - \t ***** Running Inference on 5 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d46fc56cb6a4b55b849c00122e9aabe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/02/2024 11:58:10 - INFO - \t Tokenize 5 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7bebda846d44306933699dc14fae78b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/02/2024 11:58:13 - INFO - \t ***** Running Inference on 5 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b6a314149d84ea488f6243d4cd3c57f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">====== 30 articles processed ======<\n",
      "27.239612579345703\n"
     ]
    }
   ],
   "source": [
    "# Set the model name for named entity recognition and coreference resolution\n",
    "cr_model_name = 'fastcoref' # 'lingmess'\n",
    "\n",
    "cr_tagger, cr_model_name = cr.setup_cr_tagger(model_name = cr_model_name)\n",
    "\n",
    "# And then run the model to add NER's to the articles\n",
    "num_articles = len(articles)\n",
    "batch_size = 50\n",
    "start_indices = list(range(0, num_articles, 50))\n",
    "end_indices = start_indices[1:] + [num_articles]\n",
    "batches = list(zip(start_indices, end_indices))\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "start_time = time.time()    \n",
    "for batch in batches:\n",
    "    cr.get_ner_cr_data(articles = articles[batch[0]:batch[1]],cr_tagger = cr_tagger)\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "    print(f'''>====== {batch[1]} articles processed ======<''')\n",
    "end_time = time.time()\n",
    "time_difference = end_time - start_time\n",
    "print(time_difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d68a09b-0076-483a-b609-a2591b66b183",
   "metadata": {},
   "source": [
    "## Run RE on articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "457b6ed8-7c9a-452e-8db1-020e9667b1be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">====== 30 articles processed ======<\n",
      "25.729116439819336\n"
     ]
    }
   ],
   "source": [
    "# Run Rebel to get the main relations of interest\n",
    "rex_model_name = 'rebel'\n",
    "\n",
    "if rex_model_name == 'rebel':\n",
    "    # Setup the required RE tagger\n",
    "    rex_tagger, rex_tokenizer, device, rex_model_name = rex.setup_rex_tagger(model_name = rex_model_name)\n",
    "\n",
    "    # And then run the model to add REs to the articles\n",
    "    start_time = time.time()\n",
    "    for i, article in enumerate(articles):\n",
    "        chunk_boundaries = chunk_long_articles(article.article_text, max_chunk_size = 20000)\n",
    "        for chunk in chunk_boundaries:\n",
    "            rex.rebel_get_relations(article = article, rex_tokenizer = rex_tokenizer, \\\n",
    "                                    rex_tagger =  rex_tagger, device = device, chunk = chunk)\n",
    "            rex.remove_self_relations(article = article)\n",
    "        # Clear the CUDA cache every 5 articles\n",
    "        if device == 'cuda' and (i + 1) % 5 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f'''>====== {i + 1} articles processed ======<''')\n",
    "    print(f'''>====== {i + 1} articles processed ======<''')\n",
    "    end_time = time.time()\n",
    "    time_difference = end_time - start_time\n",
    "    print(time_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f846481-2511-4f03-9713-a1850cf3719d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-02 11:58:56,783 SequenceTagger predicts: Dictionary with 76 tags: <unk>, O, B-CARDINAL, E-CARDINAL, S-PERSON, S-CARDINAL, S-PRODUCT, B-PRODUCT, I-PRODUCT, E-PRODUCT, B-WORK_OF_ART, I-WORK_OF_ART, E-WORK_OF_ART, B-PERSON, E-PERSON, S-GPE, B-DATE, I-DATE, E-DATE, S-ORDINAL, S-LANGUAGE, I-PERSON, S-EVENT, S-DATE, B-QUANTITY, E-QUANTITY, S-TIME, B-TIME, I-TIME, E-TIME, B-GPE, E-GPE, S-ORG, I-GPE, S-NORP, B-FAC, I-FAC, E-FAC, B-NORP, E-NORP, S-PERCENT, B-ORG, E-ORG, B-LANGUAGE, E-LANGUAGE, I-CARDINAL, I-ORG, S-WORK_OF_ART, I-QUANTITY, B-MONEY\n",
      "2024-08-02 11:58:58,654 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-08-02 11:58:58,894 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-08-02 11:58:59,510 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-08-02 11:59:00,238 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-08-02 11:59:06,285 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-08-02 11:59:08,671 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-08-02 11:59:11,286 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-08-02 11:59:12,481 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-08-02 11:59:15,316 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-08-02 11:59:16,674 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-08-02 11:59:18,568 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-08-02 11:59:19,978 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-08-02 11:59:21,740 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-08-02 11:59:29,278 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "2024-08-02 11:59:37,035 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      ">====== 30 articles processed ======<\n",
      "43.187543869018555\n"
     ]
    }
   ],
   "source": [
    "# Run Flair to get alternate_name relations\n",
    "rex_model_name = 'flair'\n",
    "\n",
    "if rex_model_name == 'flair':\n",
    "    # Setup the required RE tagger\n",
    "    rex_tagger, ner_tagger, splitter, device, model_name = rex.setup_rex_tagger(model_name = rex_model_name)\n",
    "    \n",
    "    # And then run the model to add REs to the articles\n",
    "    start_time = time.time()\n",
    "    for i, article in enumerate(articles):\n",
    "        rex.flair_get_relations(article = article, splitter  = splitter, ner_tagger  = ner_tagger, \\\n",
    "                                rex_tagger = rex_tagger, device = device, restricted = True)\n",
    "        rex.remove_self_relations(article = article)\n",
    "        # Clear the CUDA cache every 5 articles\n",
    "        if device == 'cuda' and (i + 1) % 5 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f'''>====== {i + 1} articles processed ======<''')\n",
    "    print(f'''>====== {i + 1} articles processed ======<''')\n",
    "    end_time = time.time()\n",
    "    time_difference = end_time - start_time\n",
    "    print(time_difference)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7787198c-2078-4436-a692-2cf13118f92b",
   "metadata": {},
   "source": [
    "## Write to Pickle\n",
    "\n",
    "(We don't need the JSON format now as we are done with Label Studio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3185f6b0-cefa-4c60-ad1c-30da50b8e5fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('model_outputs/round2/results.pkl', 'wb') as file:\n",
    "    # Write the objects to the file\n",
    "    pickle.dump(articles, file)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m120"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
