{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7a8e8fa-b507-441b-8481-1dda8f2509b0",
   "metadata": {},
   "source": [
    "# Round 1 Initial model outputs\n",
    "\n",
    "For Round 1 the following needed to be run and evaluated:\n",
    "\n",
    "__NER:__\n",
    "\n",
    "- spaCy en_core_web_trf (used as basis for annotation)\n",
    "- flair/ner-english-ontonotes-large\n",
    "\n",
    "__CR:__\n",
    "\n",
    "- fastcoref (used as basis for annotation)\n",
    "- LingMess\n",
    "\n",
    "__REX:__\n",
    "\n",
    "- Babelscape/rebel-large (used as basis for annotation)\n",
    "- Flair (only alternat_name included in annotations)\n",
    "\n",
    "The below code reads the selected sample data into a df which includes the following columns: \n",
    "\n",
    "- Id: unique Id for each article, e.g. _ed94c34a-8499-44f9-afb4-f8df96bb8843_\n",
    "- Permatitle: final part of article URL, e.g. _zondo-commission-to-issue-a-summons-for-jacob-zuma-to-appear-20200110_\n",
    "- SampleType: one of _general_, _analysis_, or _opinion_ indicating the type of article\n",
    "- AllText: a combination of _Title_, _Synopsis_ and _CleanBody_ (article text pre-stripped of HTML tags)\n",
    "- Split: one of _train_ or _test_\n",
    "\n",
    "It then generates model outputs for each of the 3 tasks listed above (adjust model names as required) and generates label-studio ready json files to enable annotation.\n",
    "\n",
    "When running on GPU one can use ```watch -n 1 nvidia-smi``` to monitor GPU usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4842942-09c1-4043-bc3d-52e2ab7addea",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aa8382c-55a8-4c61-b1e5-cbb6ecb5e50c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import torch\n",
    "from kg_builder import kg\n",
    "from kg_builder import ner\n",
    "from kg_builder import cr\n",
    "from kg_builder import rex\n",
    "from kg_builder import get_wd_relation_data\n",
    "from kg_builder import chunk_long_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fb7031-9a38-474e-ad73-12e36acfc0e5",
   "metadata": {},
   "source": [
    "## Import data and make Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deb51dcf-3600-4d8a-87ce-b3ec460a854a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import sample data\n",
    "df = pd.read_parquet('source_data/sample_text_30.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cd6955d-8900-43b3-a35f-e3267f4f3a66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make a list of Article instances\n",
    "articles = kg.make_articles(df=df)\n",
    "\n",
    "# Just get 3 to test with on CPU - comment out for full run\n",
    "# articles = articles[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d836abf-78e5-4044-bcca-9f09adddbc2d",
   "metadata": {},
   "source": [
    "## Run NER on articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ecfff19-2cbb-478c-aa00-ab65fc03ae0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">====== 30 articles processed ======<\n",
      "6.897720575332642\n",
      "\n",
      "Article b98bba34-c5d7-440b-b7a5-e365fabf4bc3\n",
      "WATCH LIVE | State capture inquiry continues\n",
      "--------------------------------------------\n",
      "PwC, ORG, [68:71]\n",
      "Pule Mothibe, PERSON, [80:92]\n",
      "PricewaterhouseCoopers, ORG, [183:205]\n",
      "Pule Mothibe, PERSON, [214:226]\n",
      "PwC, ORG, [228:231]\n",
      "South Africa, GPE, [232:244]\n",
      "Pule Mothibe, PERSON, [253:265]\n",
      "SAA, ORG, [367:370]\n",
      "PwC, ORG, [422:425]\n",
      "SAA, ORG, [434:437]\n",
      "Mothibe, PERSON, [484:491]\n",
      "SAA, ORG, [537:540]\n",
      "PricewaterhouseCoopers (, ORG, [741:765]\n",
      "PwC, ORG, [765:768]\n",
      "Pule Mothibe, PERSON, [778:790]\n",
      "Mothibe, PERSON, [793:800]\n",
      "PwC, ORG, [805:808]\n",
      "South African Airways, ORG, [832:853]\n",
      "SAA, ORG, [855:858]\n",
      "Mothibe, PERSON, [916:923]\n",
      "Kate Hofmeyr, PERSON, [967:979]\n",
      "PwC, ORG, [1023:1026]\n",
      "SAA, ORG, [1067:1070]\n",
      "Mothibe, PERSON, [1126:1133]\n",
      "SAA, ORG, [1225:1228]\n",
      "PwC, ORG, [1303:1306]\n",
      "SAA, ORG, [1425:1428]\n",
      "Transnet, ORG, [1589:1597]\n",
      "Eskom, ORG, [1620:1625]\n",
      "Mafika Mkwanazi, PERSON, [1639:1654]\n",
      "SABC, ORG, [1674:1678]\n"
     ]
    }
   ],
   "source": [
    "# Set the model name for named entity recognition as required\n",
    "ner_model_name = 'spacy' # 'flair'\n",
    "\n",
    "ner_tagger, ner_model_name = ner.setup_ner_tagger(model_name = ner_model_name)\n",
    "\n",
    "# And then run the model to add NER's to the articles\n",
    "num_articles = len(articles)\n",
    "batch_size = 50\n",
    "start_indices = list(range(0, num_articles, 50))\n",
    "end_indices = start_indices[1:] + [num_articles]\n",
    "batches = list(zip(start_indices, end_indices))\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "start_time = time.time()\n",
    "for batch in batches:\n",
    "    ner.get_entities(articles = articles[batch[0]:batch[1]], model_name = ner_model_name , ner_tagger = ner_tagger)\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "    print(f'''>====== {batch[1]} articles processed ======<''')\n",
    "end_time = time.time()\n",
    "time_difference = end_time - start_time\n",
    "print(time_difference)\n",
    "\n",
    "articles[1].print_named_entities()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f876a3c-c2b0-4cc7-ad36-8578daea947d",
   "metadata": {},
   "source": [
    "## Run CR on articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "238ceafe-31f2-43c4-bc27-e7651359f672",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "08/02/2024 12:08:32 - INFO - \t missing_keys: []\n",
      "08/02/2024 12:08:32 - INFO - \t unexpected_keys: []\n",
      "08/02/2024 12:08:32 - INFO - \t mismatched_keys: []\n",
      "08/02/2024 12:08:32 - INFO - \t error_msgs: []\n",
      "08/02/2024 12:08:32 - INFO - \t Model Parameters: 90.5M, Transformer: 82.1M, Coref head: 8.4M\n",
      "08/02/2024 12:08:33 - INFO - \t Tokenize 5 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb9678dd7b0b4277b5443959b13e8953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/02/2024 12:08:36 - INFO - \t ***** Running Inference on 5 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab0921f209a4ff7a6dfe46288bc647b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/02/2024 12:08:36 - INFO - \t Tokenize 5 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce465ad0772347a39f49335a67b7767c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/02/2024 12:08:39 - INFO - \t ***** Running Inference on 5 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a569456d0a184ce18019c5b73ed1fc4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/02/2024 12:08:40 - INFO - \t Tokenize 5 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c692a7f5d041e19ce06b8c18df2633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/02/2024 12:08:43 - INFO - \t ***** Running Inference on 5 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "033d97eb8f8149f194c1af837a4f9cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/02/2024 12:08:44 - INFO - \t Tokenize 5 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b7f182fb8745f9ad4fcad2796597c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/02/2024 12:08:47 - INFO - \t ***** Running Inference on 5 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ee64285f3643feb24c961c4f33e31f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/02/2024 12:08:48 - INFO - \t Tokenize 5 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc1a6f91949b47168ac343ef75f58cc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/02/2024 12:08:51 - INFO - \t ***** Running Inference on 5 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac8b21f81554be9961bbeacf5c973c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/02/2024 12:08:53 - INFO - \t Tokenize 5 inputs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80c54dfc95c44a55913ab334bae175f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/02/2024 12:08:56 - INFO - \t ***** Running Inference on 5 texts *****\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fc774c85e564c9e9eb99e7c8ebeb6af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">====== 30 articles processed ======<\n",
      "24.030704498291016\n",
      "\n",
      "Article b98bba34-c5d7-440b-b7a5-e365fabf4bc3\n",
      "WATCH LIVE | State capture inquiry continues\n",
      "--------------------------------------------\n",
      "\n",
      "Cluster 0: \n",
      "State capture inquiry, [13:34]\n",
      "The state capture inquiry, [93:118]\n",
      "The state capture inquiry, [651:676]\n",
      "The state capture inquiry, [1526:1551]\n",
      "\n",
      "Cluster 1: \n",
      "testimony from PwC auditor Pule Mothibe, [53:92]\n",
      "aviation-related testimony from PricewaterhouseCoopers auditor Pule Mothibe, [151:226]\n",
      "aviation-related testimony from PricewaterhouseCoopers (PwC) auditor Pule Mothibe, [709:790]\n",
      "\n",
      "Cluster 2: \n",
      "PwC auditor Pule Mothibe, [68:92]\n",
      "PricewaterhouseCoopers auditor Pule Mothibe, [183:226]\n",
      "PwC South Africa auditor Pule Mothibe, [228:265]\n",
      "his, [309:312]\n",
      "Mothibe, [484:491]\n",
      "\n",
      "Cluster 3: \n",
      "SAA management, [367:381]\n",
      "it, [417:419]\n",
      "SAA management, [1225:1239]\n",
      "\n",
      "Cluster 4: \n",
      "PwC, [68:71]\n",
      "PwC, [422:425]\n",
      "PwC's, [805:810]\n",
      "PwC, [1023:1026]\n",
      "it, [1088:1090]\n",
      "\n",
      "Cluster 5: \n",
      "SAA, [367:370]\n",
      "SAA's, [434:439]\n",
      "SAA, [537:540]\n",
      "SAA, [1067:1070]\n",
      "SAA, [1225:1228]\n",
      "\n",
      "Cluster 6: \n",
      "Friday, [127:133]\n",
      "Friday, [685:691]\n",
      "\n",
      "Cluster 7: \n",
      "2014, [521:525]\n",
      "2014, [887:891]\n",
      "\n",
      "Cluster 8: \n",
      "2016, [530:534]\n",
      "2016, [896:900]\n",
      "\n",
      "Cluster 9: \n",
      "the commission, [1004:1018]\n",
      "the commission, [1147:1161]\n",
      "\n",
      "Cluster 10: \n",
      "his team, [1167:1175]\n",
      "they, [1322:1326]\n",
      "\n",
      "Cluster 11: \n",
      "December 2019, [574:587]\n",
      "December 2019, [1465:1478]\n"
     ]
    }
   ],
   "source": [
    "# Set the model name for coreference resolution as required\n",
    "cr_model_name = 'fastcoref' # 'lingmess'\n",
    "\n",
    "# Setup the required NER tagger\n",
    "cr_tagger, cr_model_name = cr.setup_cr_tagger(model_name = cr_model_name)\n",
    "\n",
    "# And then run the model to add NER's to the articles\n",
    "num_articles = len(articles)\n",
    "batch_size = 50\n",
    "start_indices = list(range(0, num_articles, 50))\n",
    "end_indices = start_indices[1:] + [num_articles]\n",
    "batches = list(zip(start_indices, end_indices))\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "start_time = time.time()    \n",
    "for batch in batches:\n",
    "    cr.get_clusters(articles = articles[batch[0]:batch[1]], model_name = cr_model_name , cr_tagger = cr_tagger)\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "    print(f'''>====== {batch[1]} articles processed ======<''')\n",
    "end_time = time.time()\n",
    "time_difference = end_time - start_time\n",
    "print(time_difference)\n",
    "\n",
    "articles[1].print_cr_clusters(post_processing = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0589ae1-e365-4bc7-bbb6-c6b0439221c8",
   "metadata": {},
   "source": [
    "## Run RE on articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdaae436-b77e-448e-a077-e0b0789e263b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">====== 30 articles processed ======<\n",
      "25.44956374168396\n",
      "\n",
      "Article b98bba34-c5d7-440b-b7a5-e365fabf4bc3\n",
      "WATCH LIVE | State capture inquiry continues\n",
      "--------------------------------------------\n",
      "Pule Mothibe >> employer >> PwC South Africa\n",
      "[80:92], [228:244]                \n",
      "Pule Mothibe >> employer >> PricewaterhouseCoopers\n",
      "[80:92], [183:205]                \n",
      "Pule Mothibe >> employer >> PricewaterhouseCoopers\n",
      "[778:790], [741:763]                \n",
      "Pule Mothibe >> employer >> PwC\n",
      "[778:790], [765:768]                \n",
      "Pule Mothibe >> employer >> PricewaterhouseCoopers (PwC)\n",
      "[778:790], [741:769]                \n",
      "Transnet >> chairperson >> Mafika Mkwanazi\n",
      "[1589:1597], [1639:1654]                \n",
      "Transnet >> parent organization >> Eskom\n",
      "[1589:1597], [1620:1625]                \n",
      "Mafika Mkwanazi >> employer >> Transnet\n",
      "[1639:1654], [1589:1597]                \n"
     ]
    }
   ],
   "source": [
    "# Set the model name for relation extraction\n",
    "rex_model_name = 'rebel' # 'flair'\n",
    "\n",
    "if rex_model_name == 'rebel':\n",
    "    # Setup the required RE tagger\n",
    "    rex_tagger, rex_tokenizer, device, rex_model_name = rex.setup_rex_tagger(model_name = rex_model_name)\n",
    "\n",
    "    # And then run the model to add REs to the articles\n",
    "    start_time = time.time()\n",
    "    for i, article in enumerate(articles):\n",
    "        chunk_boundaries = chunk_long_articles(article.article_text, max_chunk_size = 20000)\n",
    "        for chunk in chunk_boundaries:\n",
    "            rex.rebel_get_relations(article = article, rex_tokenizer = rex_tokenizer, \\\n",
    "                                    rex_tagger =  rex_tagger, device = device, chunk = chunk)\n",
    "        # Clear the CUDA cache every 5 articles\n",
    "        if device == 'cuda' and (i + 1) % 5 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f'''>====== {i + 1} articles processed ======<''')\n",
    "    print(f'''>====== {i + 1} articles processed ======<''')\n",
    "    end_time = time.time()\n",
    "    time_difference = end_time - start_time\n",
    "    print(time_difference)\n",
    "        \n",
    "elif rex_model_name == 'flair':\n",
    "    # Setup the required RE tagger\n",
    "    rex_tagger, ner_tagger, splitter, device, model_name = rex.setup_rex_tagger(model_name = rex_model_name)\n",
    "    \n",
    "    # And then run the model to add REs to the articles\n",
    "    start_time = time.time()\n",
    "    for i, article in enumerate(articles):\n",
    "        rex.flair_get_relations(article = article, splitter  = splitter, ner_tagger  = ner_tagger, \\\n",
    "                                rex_tagger = rex_tagger, device = device)\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f'''>====== {i + 1} articles processed ======<''')\n",
    "    print(f'''>====== {i + 1} articles processed ======<''')\n",
    "    end_time = time.time()\n",
    "    time_difference = end_time - start_time\n",
    "    print(time_difference)\n",
    "    \n",
    "articles[1].print_relations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c3b35b-d6dc-4cb8-bfc6-0b20997ad723",
   "metadata": {},
   "source": [
    "## Write to Label Studio json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddbe5fe6-f66f-4b02-9ca5-81908042cfaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task is 'named_entities'\n",
    "filename = f'''outputs/round1/sample_ner_30_{ner_model_name}.json'''\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump([article.to_labelstudio('named_entities') for article in articles], f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1995a575-d1f6-413e-af5a-22eb3f3e095c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task is 'cr_clusters'\n",
    "filename = f'''outputs/round1/sample_cr_30_{cr_model_name}.json'''\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump([article.to_labelstudio('cr_clusters') for article in articles], f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49e89c72-b648-4bcf-a8cc-827ce2a5df17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task is 'relations'\n",
    "filename = f'''outputs/round1/sample_re_30_{rex_model_name}.json'''\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump([article.to_labelstudio('relations') for article in articles], f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m121",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m121"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13 (Local)",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
